{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 链接家里面的Ollama服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我注意到您似乎在提及“ollama千文2模型”，但我需要更多具体的背景信息才能提供准确的帮助或解释。不过，基于您的表述，“ollama”可能是某种特定领域的术语或者特定项目的名称。“千文2”通常与文本生成、自然语言处理（NLP）相关联，可能是指某种模型或算法的版本。\\n\\n如果“ollama千文2模型”是一个特定项目或研究的一部分：\\n\\n1. **项目背景**：请提供一些关于这个模型的背景信息。例如，它是为了解决什么具体问题而开发的？在哪个领域应用？\\n\\n2. **技术细节**：如果有相关的论文、文档或报告可供参考，请分享链接或者简要描述其核心技术点。\\n\\n3. **问题或需求**：如果您有特定的技术问题或希望实现的功能，清楚地列出它们。例如：“我正在尝试使用这个模型进行文本生成，但是遇到一些性能瓶颈。”\\n\\n4. **资源查找**：如果您需要获取该模型的代码、文档或研究论文等，请提供您已经搜索过的地方或者具体说明您的需求。\\n\\n为了更有效地帮助您，我建议明确上述点中的每一项。如果您能提供更多细节，我可以为您提供更加针对性和实用的信息和支持。', response_metadata={'model': 'qwen2', 'created_at': '2024-07-11T02:23:07.380928Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 3163707100, 'load_duration': 1037700, 'prompt_eval_count': 13, 'prompt_eval_duration': 210464000, 'eval_count': 255, 'eval_duration': 2950937000}, id='run-269fa69b-c078-4613-a217-4ce1db59ef74-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 设置您的 OLLAMA API 端点\n",
    "api_url = \"https://064a-36-27-98-198.ngrok-free.app\"\n",
    "llm = ChatOllama(model=\"qwen2\",base_url=api_url)\n",
    "\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"User\",\n",
    "    \"description\": \"Identifying information about a person.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"title\": \"名字\", \"description\": \"用户名称\", \"type\": \"string\"},\n",
    "        \"age\": {\"title\": \"年龄\", \"description\": \"用户的年龄\", \"type\": \"integer\"},\n",
    "        \"fav_food\": {\n",
    "            \"title\": \"喜爱的食物\",\n",
    "            \"description\": \"该用户最喜欢的食物\",\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"返回一个用户的信息，根据我给出的JSON schema:\"\n",
    "    ),\n",
    "    HumanMessage(content=\"{dumps}\"),\n",
    "    HumanMessage(\n",
    "        content=\"#用户张翰峰，年龄35岁，喜欢吃披萨# \"\n",
    "    ),\n",
    "]\n",
    "# 初始化 OLLAMA 客户端\n",
    "# prompt = ChatPromptTemplate.from_template(\"你是张翰峰的代码开发小助手，分析解决问题的步骤，用代码和注释给出问题的解决方案，问题是 {topic}\")\n",
    "# 生成文本\n",
    "# prompt  = ChatPromptTemplate.from_messages(messages)\n",
    "# dumps = json.dumps(json_schema, indent=2)\n",
    "# chain = prompt | llm | StrOutputParser()\n",
    "# print(chain.invoke({dumps:dumps}))\n",
    "\n",
    "llm.invoke('这是我的ollama千文2模型')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiservice-hoM4jAU4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
